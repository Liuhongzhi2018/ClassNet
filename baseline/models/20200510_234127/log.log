20200510-23:42:23 ----------------------------------------------------------------------------------------------------
20200510-23:45:40 epoch:1 - train loss: 1.472 and train acc: 0.704 total sample: 1323
20200510-23:46:05 epoch:1 - test loss: 1.540 and test acc: 0.661 total sample: 560
20200510-23:46:06 ----------------------------------------------------------------------------------------------------
20200510-23:49:28 epoch:2 - train loss: 0.473 and train acc: 0.862 total sample: 1323
20200510-23:49:57 epoch:2 - test loss: 0.630 and test acc: 0.791 total sample: 560
20200510-23:49:57 ----------------------------------------------------------------------------------------------------
20200510-23:53:35 epoch:3 - train loss: 0.402 and train acc: 0.890 total sample: 1323
20200510-23:54:06 epoch:3 - test loss: 0.690 and test acc: 0.820 total sample: 560
20200510-23:54:06 ----------------------------------------------------------------------------------------------------
20200510-23:57:51 epoch:4 - train loss: 0.233 and train acc: 0.929 total sample: 1323
20200510-23:58:25 epoch:4 - test loss: 0.534 and test acc: 0.857 total sample: 560
20200510-23:58:25 ----------------------------------------------------------------------------------------------------
20200511-00:02:05 epoch:5 - train loss: 0.229 and train acc: 0.957 total sample: 1323
20200511-00:02:36 epoch:5 - test loss: 0.748 and test acc: 0.850 total sample: 560
20200511-00:02:36 ----------------------------------------------------------------------------------------------------
20200511-00:06:15 epoch:6 - train loss: 0.091 and train acc: 0.979 total sample: 1323
20200511-00:06:48 epoch:6 - test loss: 0.479 and test acc: 0.900 total sample: 560
20200511-00:06:51 ----------------------------------------------------------------------------------------------------
20200511-00:10:49 epoch:7 - train loss: 0.070 and train acc: 0.983 total sample: 1323
20200511-00:11:23 epoch:7 - test loss: 0.789 and test acc: 0.871 total sample: 560
20200511-00:11:25 ----------------------------------------------------------------------------------------------------
20200511-00:15:19 epoch:8 - train loss: 0.203 and train acc: 0.962 total sample: 1323
20200511-00:15:56 epoch:8 - test loss: 0.623 and test acc: 0.870 total sample: 560
20200511-00:15:58 ----------------------------------------------------------------------------------------------------
20200511-00:19:45 epoch:9 - train loss: 0.032 and train acc: 0.988 total sample: 1323
20200511-00:20:18 epoch:9 - test loss: 0.382 and test acc: 0.927 total sample: 560
20200511-00:20:18 ----------------------------------------------------------------------------------------------------
20200511-00:24:00 epoch:10 - train loss: 0.010 and train acc: 0.997 total sample: 1323
20200511-00:24:31 epoch:10 - test loss: 0.308 and test acc: 0.920 total sample: 560
20200511-00:24:31 ----------------------------------------------------------------------------------------------------
20200511-00:28:10 epoch:11 - train loss: 0.012 and train acc: 0.996 total sample: 1323
20200511-00:28:41 epoch:11 - test loss: 0.287 and test acc: 0.923 total sample: 560
20200511-00:28:41 ----------------------------------------------------------------------------------------------------
20200511-00:32:26 epoch:12 - train loss: 0.004 and train acc: 0.998 total sample: 1323
20200511-00:32:57 epoch:12 - test loss: 0.350 and test acc: 0.936 total sample: 560
20200511-00:32:58 ----------------------------------------------------------------------------------------------------
20200511-00:36:23 epoch:13 - train loss: 0.010 and train acc: 0.998 total sample: 1323
20200511-00:36:50 epoch:13 - test loss: 0.327 and test acc: 0.929 total sample: 560
20200511-00:36:50 ----------------------------------------------------------------------------------------------------
20200511-00:40:14 epoch:14 - train loss: 0.004 and train acc: 0.998 total sample: 1323
20200511-00:40:43 epoch:14 - test loss: 0.293 and test acc: 0.934 total sample: 560
20200511-00:40:44 ----------------------------------------------------------------------------------------------------
20200511-00:44:09 epoch:15 - train loss: 0.012 and train acc: 0.995 total sample: 1323
20200511-00:44:35 epoch:15 - test loss: 0.564 and test acc: 0.936 total sample: 560
20200511-00:44:35 ----------------------------------------------------------------------------------------------------
20200511-00:47:57 epoch:16 - train loss: 0.006 and train acc: 0.998 total sample: 1323
20200511-00:48:24 epoch:16 - test loss: 0.281 and test acc: 0.945 total sample: 560
20200511-00:48:24 ----------------------------------------------------------------------------------------------------
20200511-00:51:55 epoch:17 - train loss: 0.005 and train acc: 0.998 total sample: 1323
20200511-00:52:23 epoch:17 - test loss: 0.237 and test acc: 0.954 total sample: 560
20200511-00:52:24 ----------------------------------------------------------------------------------------------------
20200511-00:55:49 epoch:18 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-00:56:15 epoch:18 - test loss: 0.206 and test acc: 0.954 total sample: 560
20200511-00:56:15 ----------------------------------------------------------------------------------------------------
20200511-00:59:38 epoch:19 - train loss: 0.004 and train acc: 0.998 total sample: 1323
20200511-01:00:04 epoch:19 - test loss: 0.260 and test acc: 0.950 total sample: 560
20200511-01:00:04 ----------------------------------------------------------------------------------------------------
20200511-01:03:37 epoch:20 - train loss: 0.004 and train acc: 0.998 total sample: 1323
20200511-01:04:06 epoch:20 - test loss: 0.240 and test acc: 0.957 total sample: 560
20200511-01:04:06 ----------------------------------------------------------------------------------------------------
20200511-01:07:28 epoch:21 - train loss: 0.003 and train acc: 0.999 total sample: 1323
20200511-01:07:53 epoch:21 - test loss: 0.270 and test acc: 0.939 total sample: 560
20200511-01:07:53 ----------------------------------------------------------------------------------------------------
20200511-01:11:17 epoch:22 - train loss: 0.002 and train acc: 0.999 total sample: 1323
20200511-01:11:45 epoch:22 - test loss: 0.212 and test acc: 0.952 total sample: 560
20200511-01:11:46 ----------------------------------------------------------------------------------------------------
20200511-01:15:13 epoch:23 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-01:15:39 epoch:23 - test loss: 0.191 and test acc: 0.961 total sample: 560
20200511-01:15:39 ----------------------------------------------------------------------------------------------------
20200511-01:19:01 epoch:24 - train loss: 0.005 and train acc: 0.998 total sample: 1323
20200511-01:19:28 epoch:24 - test loss: 0.218 and test acc: 0.945 total sample: 560
20200511-01:19:28 ----------------------------------------------------------------------------------------------------
20200511-01:22:58 epoch:25 - train loss: 0.005 and train acc: 0.998 total sample: 1323
20200511-01:23:27 epoch:25 - test loss: 0.220 and test acc: 0.943 total sample: 560
20200511-01:23:28 ----------------------------------------------------------------------------------------------------
20200511-01:26:52 epoch:26 - train loss: 0.008 and train acc: 0.998 total sample: 1323
20200511-01:27:18 epoch:26 - test loss: 0.236 and test acc: 0.968 total sample: 560
20200511-01:27:18 ----------------------------------------------------------------------------------------------------
20200511-01:30:42 epoch:27 - train loss: 0.002 and train acc: 0.999 total sample: 1323
20200511-01:31:09 epoch:27 - test loss: 0.305 and test acc: 0.938 total sample: 560
20200511-01:31:09 ----------------------------------------------------------------------------------------------------
20200511-01:34:40 epoch:28 - train loss: 0.006 and train acc: 0.998 total sample: 1323
20200511-01:35:10 epoch:28 - test loss: 0.191 and test acc: 0.952 total sample: 560
20200511-01:35:10 ----------------------------------------------------------------------------------------------------
20200511-01:38:34 epoch:29 - train loss: 0.004 and train acc: 0.998 total sample: 1323
20200511-01:39:01 epoch:29 - test loss: 0.219 and test acc: 0.961 total sample: 560
20200511-01:39:01 ----------------------------------------------------------------------------------------------------
20200511-01:42:24 epoch:30 - train loss: 0.004 and train acc: 0.998 total sample: 1323
20200511-01:42:52 epoch:30 - test loss: 0.229 and test acc: 0.945 total sample: 560
20200511-01:42:52 ----------------------------------------------------------------------------------------------------
20200511-01:46:19 epoch:31 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-01:46:45 epoch:31 - test loss: 0.214 and test acc: 0.950 total sample: 560
20200511-01:46:45 ----------------------------------------------------------------------------------------------------
20200511-01:50:09 epoch:32 - train loss: 0.065 and train acc: 0.980 total sample: 1323
20200511-01:50:35 epoch:32 - test loss: 0.566 and test acc: 0.923 total sample: 560
20200511-01:50:35 ----------------------------------------------------------------------------------------------------
20200511-01:54:04 epoch:33 - train loss: 0.005 and train acc: 0.998 total sample: 1323
20200511-01:54:33 epoch:33 - test loss: 0.313 and test acc: 0.934 total sample: 560
20200511-01:54:34 ----------------------------------------------------------------------------------------------------
20200511-01:57:58 epoch:34 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-01:58:24 epoch:34 - test loss: 0.210 and test acc: 0.945 total sample: 560
20200511-01:58:24 ----------------------------------------------------------------------------------------------------
20200511-02:01:48 epoch:35 - train loss: 0.004 and train acc: 0.998 total sample: 1323
20200511-02:02:14 epoch:35 - test loss: 0.301 and test acc: 0.920 total sample: 560
20200511-02:02:14 ----------------------------------------------------------------------------------------------------
20200511-02:05:43 epoch:36 - train loss: 0.005 and train acc: 0.998 total sample: 1323
20200511-02:06:12 epoch:36 - test loss: 0.307 and test acc: 0.941 total sample: 560
20200511-02:06:12 ----------------------------------------------------------------------------------------------------
20200511-02:09:35 epoch:37 - train loss: 0.006 and train acc: 0.998 total sample: 1323
20200511-02:10:01 epoch:37 - test loss: 0.268 and test acc: 0.936 total sample: 560
20200511-02:10:01 ----------------------------------------------------------------------------------------------------
20200511-02:13:25 epoch:38 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-02:13:51 epoch:38 - test loss: 0.216 and test acc: 0.945 total sample: 560
20200511-02:13:51 ----------------------------------------------------------------------------------------------------
20200511-02:17:20 epoch:39 - train loss: 0.010 and train acc: 0.997 total sample: 1323
20200511-02:17:46 epoch:39 - test loss: 0.345 and test acc: 0.925 total sample: 560
20200511-02:17:46 ----------------------------------------------------------------------------------------------------
20200511-02:21:09 epoch:40 - train loss: 0.006 and train acc: 0.998 total sample: 1323
20200511-02:21:36 epoch:40 - test loss: 0.226 and test acc: 0.948 total sample: 560
20200511-02:21:36 ----------------------------------------------------------------------------------------------------
20200511-02:25:03 epoch:41 - train loss: 0.002 and train acc: 0.998 total sample: 1323
20200511-02:25:32 epoch:41 - test loss: 0.214 and test acc: 0.943 total sample: 560
20200511-02:25:33 ----------------------------------------------------------------------------------------------------
20200511-02:28:58 epoch:42 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-02:29:24 epoch:42 - test loss: 0.222 and test acc: 0.950 total sample: 560
20200511-02:29:24 ----------------------------------------------------------------------------------------------------
20200511-02:32:47 epoch:43 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-02:33:13 epoch:43 - test loss: 0.198 and test acc: 0.955 total sample: 560
20200511-02:33:13 ----------------------------------------------------------------------------------------------------
20200511-02:36:44 epoch:44 - train loss: 0.002 and train acc: 0.999 total sample: 1323
20200511-02:37:13 epoch:44 - test loss: 0.245 and test acc: 0.943 total sample: 560
20200511-02:37:14 ----------------------------------------------------------------------------------------------------
20200511-02:40:38 epoch:45 - train loss: 0.004 and train acc: 0.998 total sample: 1323
20200511-02:41:04 epoch:45 - test loss: 0.244 and test acc: 0.946 total sample: 560
20200511-02:41:04 ----------------------------------------------------------------------------------------------------
20200511-02:44:27 epoch:46 - train loss: 0.010 and train acc: 0.998 total sample: 1323
20200511-02:44:54 epoch:46 - test loss: 0.319 and test acc: 0.932 total sample: 560
20200511-02:44:54 ----------------------------------------------------------------------------------------------------
20200511-02:48:25 epoch:47 - train loss: 0.002 and train acc: 0.998 total sample: 1323
20200511-02:48:52 epoch:47 - test loss: 0.194 and test acc: 0.955 total sample: 560
20200511-02:48:52 ----------------------------------------------------------------------------------------------------
20200511-02:52:15 epoch:48 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-02:52:42 epoch:48 - test loss: 0.194 and test acc: 0.964 total sample: 560
20200511-02:52:42 ----------------------------------------------------------------------------------------------------
20200511-02:56:10 epoch:49 - train loss: 0.004 and train acc: 0.998 total sample: 1323
20200511-02:56:39 epoch:49 - test loss: 0.240 and test acc: 0.957 total sample: 560
20200511-02:56:39 ----------------------------------------------------------------------------------------------------
20200511-03:00:04 epoch:50 - train loss: 0.007 and train acc: 0.998 total sample: 1323
20200511-03:00:30 epoch:50 - test loss: 0.191 and test acc: 0.946 total sample: 560
20200511-03:00:30 ----------------------------------------------------------------------------------------------------
20200511-03:03:54 epoch:51 - train loss: 0.004 and train acc: 0.998 total sample: 1323
20200511-03:04:20 epoch:51 - test loss: 0.203 and test acc: 0.948 total sample: 560
20200511-03:04:20 ----------------------------------------------------------------------------------------------------
20200511-03:07:51 epoch:52 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-03:08:19 epoch:52 - test loss: 0.190 and test acc: 0.946 total sample: 560
20200511-03:08:20 ----------------------------------------------------------------------------------------------------
20200511-03:11:43 epoch:53 - train loss: 0.002 and train acc: 0.998 total sample: 1323
20200511-03:12:10 epoch:53 - test loss: 0.214 and test acc: 0.946 total sample: 560
20200511-03:12:10 ----------------------------------------------------------------------------------------------------
20200511-03:15:34 epoch:54 - train loss: 0.002 and train acc: 0.998 total sample: 1323
20200511-03:16:00 epoch:54 - test loss: 0.282 and test acc: 0.938 total sample: 560
20200511-03:16:00 ----------------------------------------------------------------------------------------------------
20200511-03:19:33 epoch:55 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-03:20:00 epoch:55 - test loss: 0.289 and test acc: 0.946 total sample: 560
20200511-03:20:00 ----------------------------------------------------------------------------------------------------
20200511-03:23:24 epoch:56 - train loss: 0.002 and train acc: 0.998 total sample: 1323
20200511-03:23:51 epoch:56 - test loss: 0.199 and test acc: 0.961 total sample: 560
20200511-03:23:51 ----------------------------------------------------------------------------------------------------
20200511-03:27:15 epoch:57 - train loss: 0.006 and train acc: 0.998 total sample: 1323
20200511-03:27:45 epoch:57 - test loss: 0.208 and test acc: 0.946 total sample: 560
20200511-03:27:45 ----------------------------------------------------------------------------------------------------
20200511-03:31:09 epoch:58 - train loss: 0.002 and train acc: 0.998 total sample: 1323
20200511-03:31:36 epoch:58 - test loss: 0.237 and test acc: 0.950 total sample: 560
20200511-03:31:36 ----------------------------------------------------------------------------------------------------
20200511-03:34:59 epoch:59 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-03:35:25 epoch:59 - test loss: 0.316 and test acc: 0.943 total sample: 560
20200511-03:35:26 ----------------------------------------------------------------------------------------------------
20200511-03:38:57 epoch:60 - train loss: 0.005 and train acc: 0.998 total sample: 1323
20200511-03:39:26 epoch:60 - test loss: 0.224 and test acc: 0.950 total sample: 560
20200511-03:39:26 ----------------------------------------------------------------------------------------------------
20200511-03:42:50 epoch:61 - train loss: 0.002 and train acc: 0.999 total sample: 1323
20200511-03:43:16 epoch:61 - test loss: 0.209 and test acc: 0.954 total sample: 560
20200511-03:43:16 ----------------------------------------------------------------------------------------------------
20200511-03:46:40 epoch:62 - train loss: 0.002 and train acc: 0.998 total sample: 1323
20200511-03:47:05 epoch:62 - test loss: 0.190 and test acc: 0.955 total sample: 560
20200511-03:47:06 ----------------------------------------------------------------------------------------------------
20200511-03:50:36 epoch:63 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-03:51:05 epoch:63 - test loss: 0.201 and test acc: 0.959 total sample: 560
20200511-03:51:05 ----------------------------------------------------------------------------------------------------
20200511-03:54:29 epoch:64 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-03:54:55 epoch:64 - test loss: 0.195 and test acc: 0.955 total sample: 560
20200511-03:54:55 ----------------------------------------------------------------------------------------------------
20200511-03:58:21 epoch:65 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-03:58:50 epoch:65 - test loss: 0.219 and test acc: 0.952 total sample: 560
20200511-03:58:50 ----------------------------------------------------------------------------------------------------
20200511-04:02:16 epoch:66 - train loss: 0.002 and train acc: 0.999 total sample: 1323
20200511-04:02:43 epoch:66 - test loss: 0.224 and test acc: 0.946 total sample: 560
20200511-04:02:43 ----------------------------------------------------------------------------------------------------
20200511-04:06:06 epoch:67 - train loss: 0.002 and train acc: 0.999 total sample: 1323
20200511-04:06:32 epoch:67 - test loss: 0.182 and test acc: 0.961 total sample: 560
20200511-04:06:33 ----------------------------------------------------------------------------------------------------
20200511-04:10:03 epoch:68 - train loss: 0.002 and train acc: 0.999 total sample: 1323
20200511-04:10:31 epoch:68 - test loss: 0.201 and test acc: 0.957 total sample: 560
20200511-04:10:31 ----------------------------------------------------------------------------------------------------
20200511-04:13:55 epoch:69 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-04:14:21 epoch:69 - test loss: 0.207 and test acc: 0.955 total sample: 560
20200511-04:14:21 ----------------------------------------------------------------------------------------------------
20200511-04:17:43 epoch:70 - train loss: 0.002 and train acc: 0.998 total sample: 1323
20200511-04:18:09 epoch:70 - test loss: 0.206 and test acc: 0.964 total sample: 560
20200511-04:18:09 ----------------------------------------------------------------------------------------------------
20200511-04:21:39 epoch:71 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-04:22:08 epoch:71 - test loss: 0.206 and test acc: 0.959 total sample: 560
20200511-04:22:08 ----------------------------------------------------------------------------------------------------
20200511-04:25:31 epoch:72 - train loss: 0.001 and train acc: 1.000 total sample: 1323
20200511-04:25:57 epoch:72 - test loss: 0.208 and test acc: 0.959 total sample: 560
20200511-04:25:57 ----------------------------------------------------------------------------------------------------
20200511-04:29:20 epoch:73 - train loss: 0.001 and train acc: 1.000 total sample: 1323
20200511-04:29:48 epoch:73 - test loss: 0.192 and test acc: 0.961 total sample: 560
20200511-04:29:49 ----------------------------------------------------------------------------------------------------
20200511-04:33:16 epoch:74 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-04:33:43 epoch:74 - test loss: 0.190 and test acc: 0.964 total sample: 560
20200511-04:33:43 ----------------------------------------------------------------------------------------------------
20200511-04:37:06 epoch:75 - train loss: 0.002 and train acc: 0.999 total sample: 1323
20200511-04:37:32 epoch:75 - test loss: 0.201 and test acc: 0.961 total sample: 560
20200511-04:37:32 ----------------------------------------------------------------------------------------------------
20200511-04:41:01 epoch:76 - train loss: 0.002 and train acc: 0.999 total sample: 1323
20200511-04:41:30 epoch:76 - test loss: 0.204 and test acc: 0.955 total sample: 560
20200511-04:41:30 ----------------------------------------------------------------------------------------------------
20200511-04:44:53 epoch:77 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-04:45:19 epoch:77 - test loss: 0.222 and test acc: 0.957 total sample: 560
20200511-04:45:19 ----------------------------------------------------------------------------------------------------
20200511-04:48:41 epoch:78 - train loss: 0.002 and train acc: 0.998 total sample: 1323
20200511-04:49:07 epoch:78 - test loss: 0.205 and test acc: 0.964 total sample: 560
20200511-04:49:07 ----------------------------------------------------------------------------------------------------
20200511-04:52:39 epoch:79 - train loss: 0.002 and train acc: 1.000 total sample: 1323
20200511-04:53:08 epoch:79 - test loss: 0.262 and test acc: 0.948 total sample: 560
20200511-04:53:08 ----------------------------------------------------------------------------------------------------
20200511-04:56:31 epoch:80 - train loss: 0.002 and train acc: 0.998 total sample: 1323
20200511-04:56:57 epoch:80 - test loss: 0.221 and test acc: 0.959 total sample: 560
20200511-04:56:57 ----------------------------------------------------------------------------------------------------
20200511-05:00:20 epoch:81 - train loss: 0.002 and train acc: 1.000 total sample: 1323
20200511-05:00:47 epoch:81 - test loss: 0.282 and test acc: 0.943 total sample: 560
20200511-05:00:47 ----------------------------------------------------------------------------------------------------
20200511-05:04:16 epoch:82 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-05:04:43 epoch:82 - test loss: 0.199 and test acc: 0.959 total sample: 560
20200511-05:04:43 ----------------------------------------------------------------------------------------------------
20200511-05:08:06 epoch:83 - train loss: 0.002 and train acc: 0.999 total sample: 1323
20200511-05:08:32 epoch:83 - test loss: 0.201 and test acc: 0.954 total sample: 560
20200511-05:08:32 ----------------------------------------------------------------------------------------------------
20200511-05:12:01 epoch:84 - train loss: 0.002 and train acc: 0.999 total sample: 1323
20200511-05:12:29 epoch:84 - test loss: 0.231 and test acc: 0.950 total sample: 560
20200511-05:12:29 ----------------------------------------------------------------------------------------------------
20200511-05:15:53 epoch:85 - train loss: 0.002 and train acc: 0.998 total sample: 1323
20200511-05:16:19 epoch:85 - test loss: 0.234 and test acc: 0.950 total sample: 560
20200511-05:16:19 ----------------------------------------------------------------------------------------------------
20200511-05:19:42 epoch:86 - train loss: 0.002 and train acc: 0.999 total sample: 1323
20200511-05:20:08 epoch:86 - test loss: 0.186 and test acc: 0.964 total sample: 560
20200511-05:20:08 ----------------------------------------------------------------------------------------------------
20200511-05:23:38 epoch:87 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-05:24:08 epoch:87 - test loss: 0.233 and test acc: 0.952 total sample: 560
20200511-05:24:08 ----------------------------------------------------------------------------------------------------
20200511-05:27:33 epoch:88 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-05:27:58 epoch:88 - test loss: 0.180 and test acc: 0.961 total sample: 560
20200511-05:27:58 ----------------------------------------------------------------------------------------------------
20200511-05:31:21 epoch:89 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-05:31:46 epoch:89 - test loss: 0.239 and test acc: 0.948 total sample: 560
20200511-05:31:46 ----------------------------------------------------------------------------------------------------
20200511-05:35:18 epoch:90 - train loss: 0.002 and train acc: 0.998 total sample: 1323
20200511-05:35:44 epoch:90 - test loss: 0.213 and test acc: 0.957 total sample: 560
20200511-05:35:44 ----------------------------------------------------------------------------------------------------
20200511-05:39:06 epoch:91 - train loss: 0.002 and train acc: 0.998 total sample: 1323
20200511-05:39:33 epoch:91 - test loss: 0.181 and test acc: 0.963 total sample: 560
20200511-05:39:33 ----------------------------------------------------------------------------------------------------
20200511-05:43:01 epoch:92 - train loss: 0.002 and train acc: 1.000 total sample: 1323
20200511-05:43:30 epoch:92 - test loss: 0.173 and test acc: 0.963 total sample: 560
20200511-05:43:30 ----------------------------------------------------------------------------------------------------
20200511-05:46:54 epoch:93 - train loss: 0.002 and train acc: 0.998 total sample: 1323
20200511-05:47:20 epoch:93 - test loss: 0.225 and test acc: 0.961 total sample: 560
20200511-05:47:20 ----------------------------------------------------------------------------------------------------
20200511-05:50:43 epoch:94 - train loss: 0.003 and train acc: 0.997 total sample: 1323
20200511-05:51:10 epoch:94 - test loss: 0.207 and test acc: 0.957 total sample: 560
20200511-05:51:10 ----------------------------------------------------------------------------------------------------
20200511-05:54:39 epoch:95 - train loss: 0.002 and train acc: 0.998 total sample: 1323
20200511-05:55:09 epoch:95 - test loss: 0.216 and test acc: 0.954 total sample: 560
20200511-05:55:09 ----------------------------------------------------------------------------------------------------
20200511-05:58:34 epoch:96 - train loss: 0.001 and train acc: 0.999 total sample: 1323
20200511-05:59:00 epoch:96 - test loss: 0.198 and test acc: 0.963 total sample: 560
20200511-05:59:00 ----------------------------------------------------------------------------------------------------
20200511-06:02:23 epoch:97 - train loss: 0.002 and train acc: 0.998 total sample: 1323
20200511-06:02:49 epoch:97 - test loss: 0.184 and test acc: 0.968 total sample: 560
20200511-06:02:49 ----------------------------------------------------------------------------------------------------
20200511-06:06:21 epoch:98 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-06:06:47 epoch:98 - test loss: 0.197 and test acc: 0.961 total sample: 560
20200511-06:06:47 ----------------------------------------------------------------------------------------------------
20200511-06:10:11 epoch:99 - train loss: 0.002 and train acc: 0.999 total sample: 1323
20200511-06:10:37 epoch:99 - test loss: 0.201 and test acc: 0.955 total sample: 560
20200511-06:10:37 ----------------------------------------------------------------------------------------------------
20200511-06:14:07 epoch:100 - train loss: 0.002 and train acc: 1.000 total sample: 1323
20200511-06:14:36 epoch:100 - test loss: 0.183 and test acc: 0.963 total sample: 560
20200511-06:14:36 ----------------------------------------------------------------------------------------------------
20200511-06:18:01 epoch:101 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-06:18:27 epoch:101 - test loss: 0.177 and test acc: 0.968 total sample: 560
20200511-06:18:27 ----------------------------------------------------------------------------------------------------
20200511-06:21:50 epoch:102 - train loss: 0.003 and train acc: 0.999 total sample: 1323
20200511-06:22:16 epoch:102 - test loss: 0.218 and test acc: 0.961 total sample: 560
20200511-06:22:16 ----------------------------------------------------------------------------------------------------
20200511-06:25:47 epoch:103 - train loss: 0.002 and train acc: 0.998 total sample: 1323
20200511-06:26:15 epoch:103 - test loss: 0.189 and test acc: 0.955 total sample: 560
20200511-06:26:15 ----------------------------------------------------------------------------------------------------
20200511-06:29:39 epoch:104 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-06:30:06 epoch:104 - test loss: 0.217 and test acc: 0.959 total sample: 560
20200511-06:30:06 ----------------------------------------------------------------------------------------------------
20200511-06:33:30 epoch:105 - train loss: 0.004 and train acc: 0.997 total sample: 1323
20200511-06:33:56 epoch:105 - test loss: 0.184 and test acc: 0.970 total sample: 560
20200511-06:33:56 ----------------------------------------------------------------------------------------------------
20200511-06:37:27 epoch:106 - train loss: 0.002 and train acc: 0.998 total sample: 1323
20200511-06:37:53 epoch:106 - test loss: 0.219 and test acc: 0.954 total sample: 560
20200511-06:37:53 ----------------------------------------------------------------------------------------------------
20200511-06:41:16 epoch:107 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-06:41:42 epoch:107 - test loss: 0.203 and test acc: 0.957 total sample: 560
20200511-06:41:42 ----------------------------------------------------------------------------------------------------
20200511-06:45:07 epoch:108 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-06:45:35 epoch:108 - test loss: 0.194 and test acc: 0.955 total sample: 560
20200511-06:45:35 ----------------------------------------------------------------------------------------------------
20200511-06:49:00 epoch:109 - train loss: 0.002 and train acc: 0.998 total sample: 1323
20200511-06:49:27 epoch:109 - test loss: 0.213 and test acc: 0.959 total sample: 560
20200511-06:49:27 ----------------------------------------------------------------------------------------------------
20200511-06:52:49 epoch:110 - train loss: 0.003 and train acc: 0.998 total sample: 1323
20200511-06:53:15 epoch:110 - test loss: 0.179 and test acc: 0.964 total sample: 560
20200511-06:53:15 ----------------------------------------------------------------------------------------------------
20200511-06:56:45 epoch:111 - train loss: 0.001 and train acc: 0.999 total sample: 1323
20200511-06:57:13 epoch:111 - test loss: 0.194 and test acc: 0.957 total sample: 560
20200511-06:57:13 ----------------------------------------------------------------------------------------------------
20200511-07:00:37 epoch:112 - train loss: 0.004 and train acc: 0.997 total sample: 1323
20200511-07:01:03 epoch:112 - test loss: 0.193 and test acc: 0.963 total sample: 560
20200511-07:01:03 ----------------------------------------------------------------------------------------------------
20200511-07:04:26 epoch:113 - train loss: 0.002 and train acc: 0.999 total sample: 1323
20200511-07:04:52 epoch:113 - test loss: 0.183 and test acc: 0.968 total sample: 560
20200511-07:04:52 ----------------------------------------------------------------------------------------------------
